#!/usr/bin/env python3
"""
Full end-to-end Tableau datasource comparator (updated per user requests).

Changes applied:
 1) Skip any column whose resolved DB field name or caption equals "[Migrated Data]" (case-insensitive).
 2) In "List of Matched Data sources" the Differences section is removed (only Matches shown).
 3) Rename "XML Comparison" to "Details Comparison" in the final HTML and improved extraction
    of values from inner XML â€” supports attributes (caption, schema, username, table, name)
    as well as text nodes.
 4) Robust column & metadata extraction (attributes and child tags), handles param prefixing.

Hard-coded directories (edit these to match your environment):
  - PRE_DIR  : pre-deployment .tdsx folder
  - POST_DIR : post-deployment .tdsx folder

Output:
  - datasource_comparison_report.html (created in current working directory)

Run: Save this file and run in your Python environment (PyCharm).
"""
import os
import zipfile
import xml.etree.ElementTree as ET
import html
import webbrowser

# ---------------- Configuration (edit paths to match your environment) ----------------
PRE_DIR = r"C:\Users\mr05197\PycharmProjects\pythonProject\Full Volume Release\Downloaded Content\ISTD - 31"
POST_DIR = r"C:\Users\mr05197\PycharmProjects\pythonProject\Full Volume Release\Downloaded Content\STD - FR"
OUTPUT_HTML = os.path.abspath("datasource_comparison_report.html")
# ------------------------------------------------------------------------------------

ALLOWED_DETAIL_PATHS = [
    "root/connection/relation/table",
    "root/connection/relation/text",
    "root/connection/named-connection/caption",
    "root/connection/named-connection/connection/schema",
    "root/connection/named-connection/connection/username",
    "root/object-graph/objects/object/properties/relation/table",
    "root/object-graph/objects/object/properties/relation/name",
]


# ---------------- XML utilities ----------------
def strip_namespace(elem):
    """Strip XML namespaces from tags and attribute names (in-place)."""
    if elem is None:
        return
    if isinstance(elem.tag, str) and elem.tag.startswith("{"):
        elem.tag = elem.tag.split("}", 1)[1]
    # attributes
    for k in list(elem.attrib.keys()):
        if k.startswith("{"):
            newk = k.split("}", 1)[1]
            elem.attrib[newk] = elem.attrib.pop(k)
    for child in list(elem):
        strip_namespace(child)


def extract_tds_from_tdsx(tdsx_path):
    """Extract the first .tds file text from a .tdsx (zip)."""
    if not tdsx_path or not os.path.exists(tdsx_path):
        return None
    try:
        with zipfile.ZipFile(tdsx_path, "r") as z:
            for name in z.namelist():
                if name.lower().endswith(".tds"):
                    with z.open(name) as f:
                        data = f.read()
                        return data.decode("utf-8", errors="replace")
    except Exception as e:
        print(f"ERROR: Could not read {tdsx_path}: {e}")
    return None


def parse_tds_from_string(tds_string):
    """Parse TDS XML string to ElementTree root. Strip namespaces."""
    if not tds_string:
        return None
    try:
        root = ET.fromstring(tds_string)
        strip_namespace(root)
        return root
    except Exception:
        try:
            parser = ET.XMLParser(encoding="utf-8")
            root = ET.fromstring(tds_string.encode("utf-8"), parser=parser)
            strip_namespace(root)
            return root
        except Exception as e:
            print(f"ERROR: Failed to parse TDS XML: {e}")
            return None


# ---------------- Column extraction & skipping Migrated Data ----------------
def resolve_column_key(col_elem, idx):
    """
    Resolve DB field name for <column> element. Resolution order:
      1) child <name> text
      2) attribute 'name'
      3) child <db-field-name> text
      4) child <caption> text
      5) attribute 'caption'
      6) fallback generated __unnamed_column__N

    If param-domain-type present (child or attribute) prefix 'Parameter_'.
    """
    name = (col_elem.findtext("name") or "").strip()
    if not name:
        name = (col_elem.get("name") or "").strip()
    if not name:
        name = (col_elem.findtext("db-field-name") or "").strip()
    if not name:
        name = (col_elem.findtext("caption") or "").strip()
    if not name:
        name = (col_elem.get("caption") or "").strip()
    if not name:
        name = f"__unnamed_column__{idx}"
    # param detection
    is_param = (col_elem.find("param-domain-type") is not None) or bool(col_elem.get("param-domain-type"))
    if is_param and not name.startswith("Parameter_"):
        name = "Parameter_" + name
    return name


def should_skip_column_by_migrated_marker(name_or_caption):
    """
    Return True if name_or_caption indicates a migrated-data marker to skip.
    Case-insensitive compare for '[migrated data]' (brackets included).
    """
    if not name_or_caption:
        return False
    s = str(name_or_caption).strip()
    return s.lower() == "[migrated data]" or s.lower() == "migrated data"


def get_columns(tds_root):
    """
    Extract columns as dict keyed by DB field name (resolved). Value:
        {'tableau_field_name': <caption>, 'hidden': 'Yes'|'No', 'is_parameter': bool}

    Skips columns where resolved key or caption equals '[Migrated Data]'.
    """
    columns = {}
    if tds_root is None:
        return columns
    idx = 0
    for col in tds_root.findall(".//column"):
        idx += 1
        key = resolve_column_key(col, idx)
        # caption: prefer child text then attribute
        caption = (col.findtext("caption") or "").strip()
        if not caption:
            caption = (col.get("caption") or "").strip()
        # If either resolved key or caption indicates migrated-data, skip this column
        if should_skip_column_by_migrated_marker(key) or should_skip_column_by_migrated_marker(caption):
            # Debug print - you can remove or comment out in production
            # print(f"Skipping migrated-data column: key='{key}', caption='{caption}'")
            continue
        # hidden: attribute 'hidden' or child text
        hidden_raw = col.get("hidden")
        if hidden_raw is None:
            hidden_raw = col.findtext("hidden")
        hidden = "No"
        if hidden_raw is not None:
            hidden_l = str(hidden_raw).strip().lower()
            hidden = "Yes" if hidden_l in ("true", "1", "yes") else "No"
        is_parameter = bool(col.find("param-domain-type") is not None or col.get("param-domain-type"))
        columns[key] = {"tableau_field_name": caption, "hidden": hidden, "is_parameter": is_parameter}
    return columns


# ---------------- Metadata extraction ----------------
def get_metadata_records(tds_root):
    """
    Extract metadata records keyed by remote-name. Return:
      { remote_name: { 'local_name': ..., 'local_type': ... }, ... }

    Supports:
      - <metadata-record> child elements with <remote-name>/<local-name>/<local-type>
      - <metadata-records><record> layout
      - fallback to attributes on nodes where used
    """
    results = {}
    if tds_root is None:
        return results

    # 1) direct metadata-record elements
    for rec in tds_root.findall(".//metadata-record"):
        remote = (rec.findtext("remote-name") or "").strip()
        local = (rec.findtext("local-name") or "").strip()
        ltype = (rec.findtext("local-type") or "").strip()
        # fallback to attributes
        if not remote:
            remote = (rec.get("remote-name") or rec.get("remote") or "").strip()
        if not local:
            local = (rec.get("local-name") or rec.get("local") or "").strip()
        if not ltype:
            ltype = (rec.get("local-type") or rec.get("local_type") or "").strip()
        if remote:
            results[remote] = {"local_name": local, "local_type": ltype}

    # 2) fallback layout: metadata-records/record
    for rec in tds_root.findall(".//metadata-records//record"):
        remote = (rec.findtext("remote-name") or "").strip()
        local = (rec.findtext("local-name") or "").strip()
        ltype = (rec.findtext("local-type") or "").strip()
        if not remote:
            remote = (rec.get("remote-name") or rec.get("remote") or rec.findtext("name") or "").strip()
        if not local:
            local = (rec.get("local-name") or rec.get("local") or "").strip()
        if not ltype:
            ltype = (rec.get("local-type") or rec.get("local_type") or "").strip()
        if remote:
            results[remote] = {"local_name": local, "local_type": ltype}

    return results


# ---------------- Inner XML/Details extraction ----------------
def parse_inner_xml_from_tds(tds_root):
    """
    Parse the inner/external XML inside the <xml> block if present,
    else try to reconstruct from <connection> children. Return Element root or None.
    """
    if tds_root is None:
        return None
    xml_elem = tds_root.find(".//xml")
    content = None
    if xml_elem is not None and xml_elem.text and xml_elem.text.strip():
        content = xml_elem.text.strip()
    if not content:
        conn = tds_root.find(".//connection")
        if conn is not None:
            parts = []
            for child in list(conn):
                try:
                    parts.append(ET.tostring(child, encoding="utf-8").decode("utf-8", errors="replace"))
                except Exception:
                    pass
            if parts:
                content = "<root>" + "".join(parts) + "</root>"
    if not content:
        return None
    try:
        inner_root = ET.fromstring(content)
        strip_namespace(inner_root)
        return inner_root
    except Exception:
        try:
            inner_root = ET.fromstring(f"<root>{content}</root>")
            strip_namespace(inner_root)
            return inner_root
        except Exception as e:
            print(f"ERROR: Failed to parse inner xml: {e}")
            return None


def elem_best_value(elem):
    """
    Return the most relevant value for an element:
      - prefer elem.text if non-empty,
      - else check common attribute names: 'table', 'name', 'caption', 'schema', 'username'
      - else return empty string
    """
    if elem is None:
        return ""
    text = (elem.text or "").strip()
    if text:
        return text
    # check attributes in order
    for attr in ("table", "name", "caption", "schema", "username", "connection"):
        v = elem.get(attr)
        if v:
            return v.strip()
    # fallback: join all attributes if present
    if elem.attrib:
        # create compact repr "k=v;..."
        parts = [f"{k}={v}" for k, v in elem.attrib.items()]
        return ";".join(parts)
    return ""


def get_allowed_detail_values(inner_root):
    """
    For each ALLOWED_DETAIL_PATHS entry, return list of values found (document order).
    Values are extracted via elem_best_value() so attributes are considered.
    Returns dict: path -> [val, ...]
    """
    results = {p: [] for p in ALLOWED_DETAIL_PATHS}
    if inner_root is None:
        return results
    for path in ALLOWED_DETAIL_PATHS:
        parts = path.split("/")
        # Build an xpath relative search for the non-root portion
        xpath = ".//" + "/".join(parts[1:]) if parts[0] == inner_root.tag else ".//" + "/".join(parts)
        try:
            found = inner_root.findall(xpath)
        except Exception:
            # fallback to find by last tag name
            found = inner_root.findall(".//" + parts[-1])
        for elem in found:
            val = elem_best_value(elem)
            results[path].append(val)
    return results


# ---------------- Comparison helpers ----------------
def compare_keyed_dicts(pre_dict, post_dict):
    """
    Compare two keyed dicts. Returns (matches, diffs, only_pre, only_post)
    matches: [(key, pre_val, post_val), ...] where pre_val == post_val
    diffs: [(key, pre_val, post_val), ...] where differ
    only_pre: [(key, pre_val), ...]
    only_post: [(key, post_val), ...]
    """
    matches, diffs, only_pre, only_post = [], [], [], []
    pre_keys, post_keys = set(pre_dict.keys()), set(post_dict.keys())
    for k in sorted(pre_keys & post_keys):
        if pre_dict[k] == post_dict[k]:
            matches.append((k, pre_dict[k], post_dict[k]))
        else:
            diffs.append((k, pre_dict[k], post_dict[k]))
    for k in sorted(pre_keys - post_keys):
        only_pre.append((k, pre_dict[k]))
    for k in sorted(post_keys - pre_keys):
        only_post.append((k, post_dict[k]))
    return matches, diffs, only_pre, only_post


def compare_lists_by_index(pre_list, post_list):
    """
    Compare two lists by index. Return (matches, diffs)
    matches: [(index, value), ...] where equal and not None
    diffs: [(index, pre_val, post_val), ...]
    """
    matches, diffs = [], []
    maxlen = max(len(pre_list), len(post_list))
    for i in range(maxlen):
        pre_val = pre_list[i] if i < len(pre_list) else None
        post_val = post_list[i] if i < len(post_list) else None
        if pre_val == post_val and pre_val is not None:
            matches.append((i, pre_val))
        else:
            diffs.append((i, pre_val, post_val))
    return matches, diffs


# ---------------- HTML builders (layout preserved, with renames/changes) ----------------
def build_column_tables_html(matches, diffs, only_pre, only_post, pre_label="Pre-Deployment", post_label="Post Deployment"):
    header = """
<table class="compare" border="1" cellspacing="0" cellpadding="4">
<thead>
<tr><th rowspan="2">DB Field Name</th><th colspan="2">%s</th><th colspan="2">%s</th></tr>
<tr><th>Tableau Field Name</th><th>Hidden</th><th>Tableau Field Name</th><th>Hidden</th></tr>
</thead>
<tbody>
""" % (pre_label, post_label)
    footer = "</tbody></table>"

    matches_rows = []
    for key, prev, postv in matches:
        pre_tf = html.escape(prev.get("tableau_field_name", "")) if prev else ""
        pre_hidden = html.escape(prev.get("hidden", "")) if prev else ""
        post_tf = html.escape(postv.get("tableau_field_name", "")) if postv else ""
        post_hidden = html.escape(postv.get("hidden", "")) if postv else ""
        matches_rows.append(f"<tr><td>{html.escape(key)}</td><td>{pre_tf}</td><td>{pre_hidden}</td><td>{post_tf}</td><td>{post_hidden}</td></tr>")

    diffs_rows = []
    for key, prev, postv in diffs:
        pre_tf = html.escape(prev.get("tableau_field_name", "")) if prev else ""
        pre_hidden = html.escape(prev.get("hidden", "")) if prev else ""
        post_tf = html.escape(postv.get("tableau_field_name", "")) if postv else ""
        post_hidden = html.escape(postv.get("hidden", "")) if postv else ""
        diffs_rows.append(f"<tr><td>{html.escape(key)}</td><td>{pre_tf}</td><td>{pre_hidden}</td><td>{post_tf}</td><td>{post_hidden}</td></tr>")

    for key, prev in only_pre:
        pre_tf = html.escape(prev.get("tableau_field_name", "")) if prev else ""
        pre_hidden = html.escape(prev.get("hidden", "")) if prev else ""
        diffs_rows.append(f"<tr><td>{html.escape(key)}</td><td>{pre_tf}</td><td>{pre_hidden}</td><td></td><td></td></tr>")

    for key, postv in only_post:
        post_tf = html.escape(postv.get("tableau_field_name", "")) if postv else ""
        post_hidden = html.escape(postv.get("hidden", "")) if postv else ""
        diffs_rows.append(f"<tr><td>{html.escape(key)}</td><td></td><td></td><td>{post_tf}</td><td>{post_hidden}</td></tr>")

    matches_html = header + ("".join(matches_rows) if matches_rows else '<tr><td colspan="5"><em>No matching columns</em></td></tr>') + footer
    diffs_html = header + ("".join(diffs_rows) if diffs_rows else '<tr><td colspan="5"><em>No differences</em></td></tr>') + footer
    return matches_html, diffs_html


def build_metadata_tables_html(matches, diffs, only_pre, only_post, pre_label="Pre-Deployment", post_label="Post Deployment"):
    header = """
<table class="compare" border="1" cellspacing="0" cellpadding="4">
<thead>
<tr><th rowspan="2">DB Field Name</th><th colspan="2">%s</th><th colspan="2">%s</th></tr>
<tr><th>Tableau Remote Field Name</th><th>Data type</th><th>Tableau Remote Field Name</th><th>Data type</th></tr>
</thead>
<tbody>
""" % (pre_label, post_label)
    footer = "</tbody></table>"

    matches_rows = []
    for key, prev, postv in matches:
        pre_local = html.escape(prev.get("local_name", "")) if prev else ""
        pre_type = html.escape(prev.get("local_type", "")) if prev else ""
        post_local = html.escape(postv.get("local_name", "")) if postv else ""
        post_type = html.escape(postv.get("local_type", "")) if postv else ""
        matches_rows.append(f"<tr><td>{html.escape(key)}</td><td>{pre_local}</td><td>{pre_type}</td><td>{post_local}</td><td>{post_type}</td></tr>")

    diffs_rows = []
    for key, prev, postv in diffs:
        pre_local = html.escape(prev.get("local_name", "")) if prev else ""
        pre_type = html.escape(prev.get("local_type", "")) if prev else ""
        post_local = html.escape(postv.get("local_name", "")) if postv else ""
        post_type = html.escape(postv.get("local_type", "")) if postv else ""
        diffs_rows.append(f"<tr><td>{html.escape(key)}</td><td>{pre_local}</td><td>{pre_type}</td><td>{post_local}</td><td>{post_type}</td></tr>")

    for key, prev in only_pre:
        pre_local = html.escape(prev.get("local_name", "")) if prev else ""
        pre_type = html.escape(prev.get("local_type", "")) if prev else ""
        diffs_rows.append(f"<tr><td>{html.escape(key)}</td><td>{pre_local}</td><td>{pre_type}</td><td></td><td></td></tr>")

    for key, postv in only_post:
        post_local = html.escape(postv.get("local_name", "")) if postv else ""
        post_type = html.escape(postv.get("local_type", "")) if postv else ""
        diffs_rows.append(f"<tr><td>{html.escape(key)}</td><td></td><td></td><td>{post_local}</td><td>{post_type}</td></tr>")

    matches_html = header + ("".join(matches_rows) if matches_rows else '<tr><td colspan="5"><em>No matching metadata</em></td></tr>') + footer
    diffs_html = header + ("".join(diffs_rows) if diffs_rows else '<tr><td colspan="5"><em>No differences</em></td></tr>') + footer
    return matches_html, diffs_html


def build_details_tables_html(matches_by_path, diffs_by_path):
    """
    Build Details Comparison tables (renamed from XML Comparison).
    Renders a single 3-column table per Matches/Differences with Attribute | Pre Deployment | Post Deployment.
    """
    def build_table(rows, headers=("Attribute", "Pre Deployment", "Post Deployment")):
        h = '<table border="1" cellpadding="6" cellspacing="0">'
        h += '<thead><tr>' + ''.join(f'<th>{html.escape(col)}</th>' for col in headers) + '</tr></thead><tbody>'
        if not rows:
            h += f'<tr><td colspan="{len(headers)}"><em>No entries</em></td></tr>'
        else:
            for attr, pre, post in rows:
                h += f'<tr><td>{html.escape(attr)}</td><td>{html.escape(pre or "Not Present")}</td><td>{html.escape(post or "Not Present")}</td></tr>'
        h += '</tbody></table>'
        return h

    matches_rows = []
    diffs_rows = []
    for path in ALLOWED_DETAIL_PATHS:
        matches = matches_by_path.get(path, [])
        diffs = diffs_by_path.get(path, [])
        # Matches
        for idx, val in matches:
            attr = path if len(matches) <= 1 else f"{path}[{idx}]"
            matches_rows.append((attr, val, val))
        # Diffs
        for idx, pre, post in diffs:
            attr = path if len(diffs) <= 1 else f"{path}[{idx}]"
            diffs_rows.append((attr, pre or "Not Present", post or "Not Present"))

    matches_html = build_table(matches_rows)
    diffs_html = build_table(diffs_rows)
    return matches_html, diffs_html


# ---------------- Report generation ----------------
def generate_html_report(results, output_path):
    total = results.get("total", 0)
    entries = results.get("entries", [])
    matched = [e for e in entries if e["is_matched"]]
    unmatched = [e for e in entries if not e["is_matched"]]

    html_parts = []
    html_parts.append('<!doctype html><html><head><meta charset="utf-8"><title>Data source comparison report</title>')
    html_parts.append('<style> body{font-family:Arial,Helvetica,sans-serif;padding:20px} table.compare{border-collapse:collapse;width:100%;margin-bottom:10px} table.compare th{background:#eee} details{margin-bottom:6px;padding:4px} table{width:100%;border-collapse:collapse} th{background:#e6f2ff} td, th{border:1px solid #999;padding:6px}</style>')
    html_parts.append('</head><body>')
    html_parts.append('<h1>Data source comparison report</h1>')
    html_parts.append(f'<p>Total number of Data sources compared: <strong>{total}</strong><br>')
    html_parts.append(f'Total number of matched Data sources: <strong>{len(matched)}</strong><br>')
    html_parts.append(f'Total number of unmatched Data sources: <strong>{len(unmatched)}</strong></p>')

    # Unmatched Data sources (full drilldowns)
    html_parts.append('<h2>List of Unmatched Data sources</h2>')
    if unmatched:
        html_parts.append('<ol>')
        for entry in unmatched:
            name = entry["name"]
            comps = entry["comparisons"]
            html_parts.append(f'<li><details><summary>{html.escape(name)}</summary>')
            # Column Comparison
            col = comps["columns"]
            col_matches_html, col_diffs_html = build_column_tables_html(col["matches"], col["diffs"], col["only_pre"], col["only_post"])
            html_parts.append('<h4>Column Comparison</h4>')
            html_parts.append('<details><summary>Matches</summary>')
            html_parts.append(col_matches_html)
            html_parts.append('</details>')
            html_parts.append('<details><summary>Differences</summary>')
            html_parts.append(col_diffs_html)
            html_parts.append('</details>')
            # Metadata Comparison
            md = comps["metadata"]
            md_matches_html, md_diffs_html = build_metadata_tables_html(md["matches"], md["diffs"], md["only_pre"], md["only_post"])
            html_parts.append('<h4>Metadata Comparison</h4>')
            html_parts.append('<details><summary>Matches</summary>')
            html_parts.append(md_matches_html)
            html_parts.append('</details>')
            html_parts.append('<details><summary>Differences</summary>')
            html_parts.append(md_diffs_html)
            html_parts.append('</details>')
            # Details Comparison (renamed from XML)
            xmlc = comps["xml"]
            details_matches_html, details_diffs_html = build_details_tables_html(xmlc["matches_by_path"], xmlc["diffs_by_path"])
            html_parts.append('<h4>Details Comparison</h4>')
            html_parts.append('<details><summary>Matches</summary>')
            html_parts.append(details_matches_html)
            html_parts.append('</details>')
            html_parts.append('<details><summary>Differences</summary>')
            html_parts.append(details_diffs_html)
            html_parts.append('</details>')
            html_parts.append('</details></li>')
        html_parts.append('</ol>')
    else:
        html_parts.append('<p><em>No unmatched data sources.</em></p>')

    # Matched Data sources (only show Matches; Differences removed)
    html_parts.append('<h2>List of Matched Data sources</h2>')
    if matched:
        html_parts.append('<ol>')
        for entry in matched:
            name = entry["name"]
            comps = entry["comparisons"]
            html_parts.append(f'<li><details open><summary>{html.escape(name)}</summary>')
            # Columns - only Matches
            col = comps["columns"]
            col_matches_html, _ = build_column_tables_html(col["matches"], col["diffs"], col["only_pre"], col["only_post"])
            html_parts.append('<h4>Column Comparison</h4>')
            html_parts.append('<details open><summary>Matches</summary>')
            html_parts.append(col_matches_html)
            html_parts.append('</details>')
            # Metadata - only Matches
            md = comps["metadata"]
            md_matches_html, _ = build_metadata_tables_html(md["matches"], md["diffs"], md["only_pre"], md["only_post"])
            html_parts.append('<h4>Metadata Comparison</h4>')
            html_parts.append('<details open><summary>Matches</summary>')
            html_parts.append(md_matches_html)
            html_parts.append('</details>')
            # Details - only Matches
            xmlc = comps["xml"]
            details_matches_html, _ = build_details_tables_html(xmlc["matches_by_path"], xmlc["diffs_by_path"])
            html_parts.append('<h4>Details Comparison</h4>')
            html_parts.append('<details open><summary>Matches</summary>')
            html_parts.append(details_matches_html)
            html_parts.append('</details>')
            html_parts.append('</details></li>')
        html_parts.append('</ol>')
    else:
        html_parts.append('<p><em>No matched data sources.</em></p>')

    html_parts.append('</body></html>')

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(html_parts))
    print(f"INFO: Wrote report: {output_path}")


# ---------------- Core comparison flow ----------------
def compare_two_datasources(pre_tds_root, post_tds_root):
    # Columns
    pre_cols = get_columns(pre_tds_root)
    post_cols = get_columns(post_tds_root)
    col_matches, col_diffs, col_only_pre, col_only_post = compare_keyed_dicts(pre_cols, post_cols)

    # Metadata
    pre_md = get_metadata_records(pre_tds_root)
    post_md = get_metadata_records(post_tds_root)
    md_matches, md_diffs, md_only_pre, md_only_post = compare_keyed_dicts(pre_md, post_md)

    # Details (inner xml)
    pre_inner = parse_inner_xml_from_tds(pre_tds_root)
    post_inner = parse_inner_xml_from_tds(post_tds_root)
    pre_details = get_allowed_detail_values(pre_inner)
    post_details = get_allowed_detail_values(post_inner)

    matches_by_path, diffs_by_path = {}, {}
    for path in ALLOWED_DETAIL_PATHS:
        pre_list = pre_details.get(path, [])
        post_list = post_details.get(path, [])
        m, d = compare_lists_by_index(pre_list, post_list)
        matches_by_path[path], diffs_by_path[path] = m, d

    comparison_summary = {
        "columns": {"matches": col_matches, "diffs": col_diffs, "only_pre": col_only_pre, "only_post": col_only_post},
        "metadata": {"matches": md_matches, "diffs": md_diffs, "only_pre": md_only_pre, "only_post": md_only_post},
        "xml": {"matches_by_path": matches_by_path, "diffs_by_path": diffs_by_path},
    }

    has_col_diff = bool(col_diffs or col_only_pre or col_only_post)
    has_md_diff = bool(md_diffs or md_only_pre or md_only_post)
    has_xml_diff = any(diffs_by_path[path] for path in ALLOWED_DETAIL_PATHS)
    is_matched = not (has_col_diff or has_md_diff or has_xml_diff)

    return comparison_summary, is_matched


def compare_keyed_dicts(pre_dict, post_dict):
    """Utility used elsewhere (kept local duplicate for clarity)."""
    matches, diffs, only_pre, only_post = [], [], [], []
    pre_keys, post_keys = set(pre_dict.keys()), set(post_dict.keys())
    for k in sorted(pre_keys & post_keys):
        if pre_dict[k] == post_dict[k]:
            matches.append((k, pre_dict[k], post_dict[k]))
        else:
            diffs.append((k, pre_dict[k], post_dict[k]))
    for k in sorted(pre_keys - post_keys):
        only_pre.append((k, pre_dict[k]))
    for k in sorted(post_keys - pre_keys):
        only_post.append((k, post_dict[k]))
    return matches, diffs, only_pre, only_post


# ---------------- File collection helpers ----------------
def collect_tdsx_files(directory):
    """Collect .tdsx files in a directory and return dict basename->fullpath."""
    files = {}
    if not directory or not os.path.isdir(directory):
        return files
    for fname in os.listdir(directory):
        if fname.lower().endswith(".tdsx"):
            key = os.path.splitext(fname)[0]
            files[key] = os.path.join(directory, fname)
    return files


# ---------------- Main ----------------
def main():
    pre_files = collect_tdsx_files(PRE_DIR)
    post_files = collect_tdsx_files(POST_DIR)
    print(f"DEBUG: Pre files = {len(pre_files)}, Post files = {len(post_files)}")
    if not pre_files and not post_files:
        print("WARNING: No .tdsx files found in either folder. Check PRE_DIR/POST_DIR configuration.")

    all_keys = sorted(set(pre_files.keys()) | set(post_files.keys()))
    total = len(all_keys)
    entries = []

    for key in all_keys:
        pre_path = pre_files.get(key)
        post_path = post_files.get(key)
        print(f"DEBUG: Processing '{key}' -- pre: {bool(pre_path)} post: {bool(post_path)}")

        pre_root = None
        post_root = None

        if pre_path:
            tds_str = extract_tds_from_tdsx(pre_path)
            if tds_str is None:
                print(f"DEBUG: Failed to extract pre .tds for {key} from {pre_path}")
            pre_root = parse_tds_from_string(tds_str) if tds_str else None

        if post_path:
            tds_str = extract_tds_from_tdsx(post_path)
            if tds_str is None:
                print(f"DEBUG: Failed to extract post .tds for {key} from {post_path}")
            post_root = parse_tds_from_string(tds_str) if tds_str else None

        comps, is_matched = compare_two_datasources(pre_root, post_root)

        # Debug counts
        col = comps["columns"]
        md = comps["metadata"]
        xmlc = comps["xml"]
        col_match_count = len(col.get("matches") or [])
        col_diff_count = len(col.get("diffs") or []) + len(col.get("only_pre") or []) + len(col.get("only_post") or [])
        md_match_count = len(md.get("matches") or [])
        md_diff_count = len(md.get("diffs") or []) + len(md.get("only_pre") or []) + len(md.get("only_post") or [])
        xml_diff_count = sum(len(xmlc["diffs_by_path"].get(p, [])) for p in xmlc["diffs_by_path"])
        xml_match_count = sum(len(xmlc["matches_by_path"].get(p, [])) for p in xmlc["matches_by_path"])
        print(f"DEBUG: '{key}': cols matched={col_match_count}, cols diffs={col_diff_count}; md matched={md_match_count}, md diffs={md_diff_count}; xml matched={xml_match_count}, xml diffs={xml_diff_count}; is_matched={is_matched}")

        entries.append({"name": key, "comparisons": comps, "is_matched": is_matched})

    matched_count = sum(1 for e in entries if e["is_matched"])
    unmatched_count = sum(1 for e in entries if not e["is_matched"])
    print(f"DEBUG: Total={total}, Matched={matched_count}, Unmatched={unmatched_count}")

    results = {"total": total, "entries": entries}
    generate_html_report(results, OUTPUT_HTML)

    # Auto-open report
    if os.path.exists(OUTPUT_HTML):
        webbrowser.open(f"file://{OUTPUT_HTML}")
        print(f"INFO: Opened report: {OUTPUT_HTML}")
    else:
        print("ERROR: Report file not found after generation.")


if __name__ == "__main__":
    main()
